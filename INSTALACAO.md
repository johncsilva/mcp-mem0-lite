# Guia de Instala√ß√£o - MCP Mem0-Lite

> **Guia completo para instala√ß√£o do servidor MCP Mem0-Lite em uma m√°quina Windows limpa**

---

## üìã √çndice

1. [Pr√©-requisitos](#pr√©-requisitos)
2. [Instala√ß√£o do Python](#1-instala√ß√£o-do-python)
3. [Instala√ß√£o do Ollama](#2-instala√ß√£o-do-ollama)
4. [Download dos Modelos LLM](#3-download-dos-modelos-llm)
5. [Configura√ß√£o do Projeto](#4-configura√ß√£o-do-projeto)
6. [Instala√ß√£o das Depend√™ncias Python](#5-instala√ß√£o-das-depend√™ncias-python)
7. [Configura√ß√£o do Ambiente](#6-configura√ß√£o-do-ambiente)
8. [Configura√ß√£o dos Clientes MCP](#7-configura√ß√£o-dos-clientes-mcp)
9. [Iniciando o Servidor](#8-iniciando-o-servidor)
10. [Verifica√ß√£o da Instala√ß√£o](#9-verifica√ß√£o-da-instala√ß√£o)
11. [Troubleshooting](#troubleshooting)

---

## Pr√©-requisitos

### Hardware M√≠nimo Recomendado
- **CPU**: 4 cores (Intel i5/AMD Ryzen 5 ou superior)
- **RAM**: 16 GB (m√≠nimo 8 GB)
- **Disco**: 20 GB de espa√ßo livre
- **GPU** (opcional): NVIDIA RTX para acelera√ß√£o (10-30x mais r√°pido)

### Software
- Windows 10/11 (64-bit)
- Conex√£o com internet (para download inicial)
- Privil√©gios de administrador (para instala√ß√£o)

### Verifica√ß√£o do Sistema

Abra o PowerShell e verifique:

```powershell
# Verificar vers√£o do Windows
systeminfo | findstr /B /C:"OS Name" /C:"OS Version"

# Verificar mem√≥ria RAM
systeminfo | findstr /C:"Total Physical Memory"

# Verificar espa√ßo em disco (unidade C:)
wmic logicaldisk where "DeviceID='C:'" get Size,FreeSpace
```

---

## 1. Instala√ß√£o do Python

### 1.1 Download do Python 3.12

1. Acesse: https://www.python.org/downloads/
2. Baixe **Python 3.12.x** (vers√£o mais recente da s√©rie 3.12)
3. Execute o instalador `python-3.12.x-amd64.exe`

### 1.2 Instala√ß√£o

‚ö†Ô∏è **IMPORTANTE**: Durante a instala√ß√£o:

‚úÖ **MARQUE** a op√ß√£o: **"Add Python 3.12 to PATH"**
‚úÖ Selecione: **"Install Now"** ou **"Customize installation"**

Se escolher "Customize installation":
- ‚úÖ Marque todas as op√ß√µes em "Optional Features"
- ‚úÖ Em "Advanced Options", marque:
  - "Install for all users"
  - "Add Python to environment variables"
  - "Precompile standard library"

### 1.3 Verifica√ß√£o

Abra um **novo** PowerShell e execute:

```powershell
python --version
# Deve retornar: Python 3.12.x

pip --version
# Deve retornar: pip 24.x.x from ...
```

‚ùå **Se n√£o funcionar**:
- Feche e reabra o PowerShell
- Se ainda n√£o funcionar, reinicie o computador

---

## 2. Instala√ß√£o do Ollama

### 2.1 Download

1. Acesse: https://ollama.com/download
2. Clique em **"Download for Windows"**
3. Baixe o arquivo `OllamaSetup.exe`

### 2.2 Instala√ß√£o

1. Execute `OllamaSetup.exe`
2. Siga o assistente de instala√ß√£o (Next ‚Üí Install ‚Üí Finish)
3. Ollama ser√° instalado e iniciado automaticamente

### 2.3 Verifica√ß√£o

Abra um **novo** PowerShell e execute:

```powershell
ollama --version
# Deve retornar: ollama version x.x.x
```

Para verificar se o servidor Ollama est√° rodando:

```powershell
curl http://127.0.0.1:11434/api/tags
```

‚úÖ **Se retornar JSON** ‚Üí Ollama est√° rodando
‚ùå **Se falhar** ‚Üí Execute: `ollama serve` em um terminal separado

---

## 3. Download dos Modelos LLM

Os modelos s√£o necess√°rios para o funcionamento do Mem0-Lite.

### 3.1 Modelo LLM (Processamento de Mem√≥rias)

**Modelo recomendado**: `llama3.2:latest` (3B par√¢metros, ~2GB)

```powershell
ollama pull llama3.2:latest
```

‚è±Ô∏è **Tempo estimado**: 5-15 minutos (depende da conex√£o)

> **Nota**: `tinyllama` √© mais r√°pido (~10s por mem√≥ria) mas pode falhar ao gerar IDs estruturados. Use `llama3.2:latest` (~35s por mem√≥ria) para maior confiabilidade.

### 3.2 Modelo de Embeddings (Busca Vetorial)

**Modelo obrigat√≥rio**: `nomic-embed-text` (768 dimens√µes, ~274MB)

```powershell
ollama pull nomic-embed-text
```

‚è±Ô∏è **Tempo estimado**: 1-3 minutos

### 3.3 Verifica√ß√£o dos Modelos

```powershell
ollama list
```

‚úÖ **Deve listar**:
```
NAME                    ID              SIZE    MODIFIED
llama3.2:latest         a80c4f17acd5    2.0 GB  X minutes ago
nomic-embed-text:latest 0a109f422b47    274 MB  X minutes ago
```

---

## 4. Configura√ß√£o do Projeto

### 4.1 Escolha do Diret√≥rio

Escolha onde instalar o projeto. Exemplo: `C:\Dev\mcp-mem0-lite`

```powershell
# Criar diret√≥rio
mkdir C:\Dev\mcp-mem0-lite
cd C:\Dev\mcp-mem0-lite
```

### 4.2 Copiar Arquivos do Projeto

**Op√ß√£o A: Se voc√™ tem os arquivos em outra m√°quina**

1. Copie toda a pasta `mcp-mem0-lite` da m√°quina de origem
2. Cole em `C:\Dev\` na m√°quina de destino
3. **Exclua** as seguintes pastas (se existirem):
   - `.venv/` (ambiente virtual - ser√° recriado)
   - `chroma_db/` (banco de dados - ser√° recriado)
   - `mem0.db` (banco de dados - ser√° recriado)

**Op√ß√£o B: Se voc√™ tem os arquivos compactados**

1. Extraia o arquivo `.zip` em `C:\Dev\`
2. Certifique-se de que a estrutura seja: `C:\Dev\mcp-mem0-lite\server.py`

### 4.3 Estrutura de Arquivos Necess√°ria

Verifique se voc√™ tem os seguintes arquivos:

```
C:\Dev\mcp-mem0-lite\
‚îú‚îÄ‚îÄ server.py              ‚úÖ (Servidor MCP principal)
‚îú‚îÄ‚îÄ .env                   ‚úÖ (Configura√ß√µes)
‚îú‚îÄ‚îÄ start_mcp.bat          ‚úÖ (Script de inicializa√ß√£o)
‚îú‚îÄ‚îÄ reset_memory.bat       ‚úÖ (Script para limpar mem√≥rias)
‚îú‚îÄ‚îÄ benchmark_speed.py     ‚≠ï (Opcional - testes de performance)
‚îú‚îÄ‚îÄ test_mcp_tools.py      ‚≠ï (Opcional - testes)
‚îú‚îÄ‚îÄ validate_mcp.py        ‚≠ï (Opcional - valida√ß√£o)
‚îî‚îÄ‚îÄ README.md              ‚≠ï (Opcional - documenta√ß√£o)
```

‚úÖ = Obrigat√≥rio | ‚≠ï = Opcional

---

## 5. Instala√ß√£o das Depend√™ncias Python

### 5.1 Criar Ambiente Virtual

```powershell
cd C:\Dev\mcp-mem0-lite
python -m venv .venv
```

### 5.2 Ativar Ambiente Virtual

```powershell
.\.venv\Scripts\Activate.ps1
```

‚ö†Ô∏è **Se aparecer erro de pol√≠tica de execu√ß√£o**:

```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

Depois execute novamente: `.\.venv\Scripts\Activate.ps1`

‚úÖ **Ambiente ativado**: O prompt deve mostrar `(.venv)` no in√≠cio

### 5.3 Atualizar pip

```powershell
python -m pip install --upgrade pip
```

### 5.4 Instalar Depend√™ncias

```powershell
pip install fastapi uvicorn python-dotenv pydantic
pip install mem0ai
pip install mcp
pip install chromadb
pip install ollama
```

‚è±Ô∏è **Tempo estimado**: 2-5 minutos

### 5.5 Verifica√ß√£o

```powershell
pip list | findstr -i "fastapi mem0 mcp chroma ollama"
```

‚úÖ **Deve listar todas as bibliotecas instaladas**

---

## 6. Configura√ß√£o do Ambiente

### 6.1 Editar o Arquivo `.env`

Abra o arquivo `.env` com o Bloco de Notas:

```powershell
notepad .env
```

### 6.2 Configurar Caminhos

**IMPORTANTE**: Ajuste os caminhos para o seu computador.

Se voc√™ instalou em `C:\Dev\mcp-mem0-lite`, mantenha assim:

```env
# MCP
HOST=127.0.0.1
PORT=8050

# Metadados (leve)
DATABASE_URL=sqlite:///C:/Dev/mcp-mem0-lite/mem0.db

# Vector store local: CHROMA
VECTOR_STORE_PROVIDER=chroma
CHROMA_PERSIST_DIR=C:/Dev/mcp-mem0-lite/chroma_db

# Embeddings via Ollama
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMS=768

# LLM local para processamento de memorias
LLM_PROVIDER=ollama
LLM_MODEL=llama3.2:latest
```

‚ö†Ô∏è **Se instalou em outro local** (ex: `D:\Projetos\mcp-mem0-lite`):
- Substitua `C:/Dev/mcp-mem0-lite` por `D:/Projetos/mcp-mem0-lite`
- **Use `/` (barra) ao inv√©s de `\` (contrabarra)** nos caminhos

### 6.3 Salvar e Fechar

1. Salve: `Ctrl+S`
2. Feche o Bloco de Notas

---

## 7. Configura√ß√£o dos Clientes MCP

Os clientes MCP (Claude Code, Gemini CLI, Codex) precisam saber onde est√° o servidor.

### 7.1 Claude Code (Obrigat√≥rio)

Claude Code usa o arquivo `~/.claude.json` para configura√ß√£o.

#### Windows

```powershell
# Abrir arquivo de configura√ß√£o
notepad "$env:USERPROFILE\.claude.json"
```

Se o arquivo n√£o existir, crie-o.

#### Adicionar Configura√ß√£o

Adicione ou edite a se√ß√£o `mcpServers`:

```json
{
  "mcpServers": {
    "mem0-lite": {
      "type": "sse",
      "url": "http://127.0.0.1:8050/mcp/sse"
    }
  }
}
```

Salve e feche.

#### Verificar Conex√£o

Ap√≥s iniciar o servidor (pr√≥ximos passos), no Claude Code execute:

```
claude mcp list
```

‚úÖ **Deve mostrar**: `mem0-lite` conectado

---

### 7.2 Gemini CLI (Opcional)

Se voc√™ usa o Gemini CLI:

```powershell
# Adicionar servidor MCP
gemini mcp add mem0-lite --scope user --command "npx" --args "-y" --args "mcp-remote@latest" --args "http://127.0.0.1:8050/mcp/sse"
```

#### Verificar

```powershell
gemini mcp list
```

‚úÖ **Deve mostrar**: `mem0-lite` (pode aparecer "Disconnected" at√© o servidor iniciar)

---

### 7.3 OpenAI Codex (Opcional)

Se voc√™ usa o Codex:

```powershell
# Adicionar servidor MCP
codex mcp add mem0-lite -- npx -y mcp-remote@latest http://127.0.0.1:8050/mcp/sse
```

#### Verificar

```powershell
codex mcp list
```

‚úÖ **Deve mostrar**: `mem0-lite` configurado

---

## 8. Iniciando o Servidor

### 8.1 Primeiro In√≠cio (Manual)

Para entender o processo, vamos iniciar manualmente:

```powershell
# Ativar ambiente virtual (se ainda n√£o estiver ativado)
.\.venv\Scripts\Activate.ps1

# Iniciar servidor
python server.py
```

‚úÖ **Servidor iniciado com sucesso** se voc√™ ver:

```
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8050 (Press CTRL+C to quit)
```

‚è±Ô∏è **Tempo de inicializa√ß√£o**: 5-10 segundos

Para parar o servidor: `Ctrl+C`

---

### 8.2 Usando o Script de Inicializa√ß√£o (Recomendado)

O script `start_mcp.bat` automatiza o processo:

1. Verifica se Ollama est√° rodando (inicia se necess√°rio)
2. Verifica se servidor MCP est√° rodando (inicia se necess√°rio)
3. Aguarda tudo ficar online
4. Mostra "TUDO OK!" quando pronto

#### Executar Script

```powershell
cd C:\Dev\mcp-mem0-lite
.\start_mcp.bat
```

#### O que esperar

```
========================================
  MCP Mem0-Lite Startup Script
========================================

[1/3] Verificando Ollama...
  [OK] Ollama ja esta rodando

[2/3] Verificando servidor MCP...
  [INICIANDO] Servidor MCP nao encontrado, iniciando...
  [OK] Servidor MCP iniciado com sucesso

[3/3] Validando integracao...
  [OK] Endpoint SSE acessivel

========================================
  TUDO OK!
========================================
  Ollama:      http://127.0.0.1:11434
  MCP Server:  http://127.0.0.1:8050
  SSE:         http://127.0.0.1:8050/mcp/sse
========================================

Pressione qualquer tecla para fechar...
```

‚ö†Ô∏è **N√£o feche a janela do servidor** - ele precisa ficar rodando em segundo plano.

---

## 9. Verifica√ß√£o da Instala√ß√£o

### 9.1 Testar Servidor MCP

Em um **novo** PowerShell:

```powershell
# Testar endpoint raiz
curl http://127.0.0.1:8050/

# Testar endpoint SSE
curl --max-time 2 http://127.0.0.1:8050/mcp/sse
```

‚úÖ **Se funcionar**: Servidor est√° respondendo

### 9.2 Testar no Claude Code

No Claude Code, execute:

```
Use o tool list_all_user_ids para listar todos os usu√°rios
```

‚úÖ **Se funcionar**: MCP est√° integrado corretamente

### 9.3 Adicionar Primeira Mem√≥ria

No Claude Code:

```
Adicione uma mem√≥ria de teste: "Instala√ß√£o do MCP Mem0-Lite conclu√≠da com sucesso!"
```

‚è±Ô∏è **Tempo esperado**: 30-40 segundos (primeira vez pode ser mais lento)

‚úÖ **Sucesso**: Claude deve confirmar que a mem√≥ria foi salva

### 9.4 Listar Mem√≥rias

```
Liste minhas mem√≥rias
```

‚úÖ **Deve retornar**: A mem√≥ria de teste que voc√™ acabou de criar

---

## Troubleshooting

### ‚ùå Problema: Python n√£o √© reconhecido

**Erro**: `'python' is not recognized as an internal or external command`

**Solu√ß√£o**:
1. Feche e reabra o PowerShell
2. Se ainda n√£o funcionar, reinicie o computador
3. Verifique se o Python est√° no PATH:
   ```powershell
   $env:PATH -split ';' | Select-String -Pattern 'Python'
   ```
4. Se n√£o aparecer, reinstale o Python marcando "Add to PATH"

---

### ‚ùå Problema: Ollama n√£o est√° respondendo

**Erro**: `Connection refused` ou `Failed to connect to Ollama`

**Solu√ß√£o**:
1. Verifique se Ollama est√° rodando:
   ```powershell
   curl http://127.0.0.1:11434/api/tags
   ```
2. Se n√£o responder, inicie manualmente:
   ```powershell
   ollama serve
   ```
3. Deixe essa janela aberta e tente novamente

---

### ‚ùå Problema: Porta 8050 j√° est√° em uso

**Erro**: `[Errno 10048] error while attempting to bind on address ('127.0.0.1', 8050)`

**Solu√ß√£o**:
1. Encontre o processo usando a porta:
   ```powershell
   netstat -ano | findstr :8050
   ```
2. Mate o processo (substitua `<PID>` pelo n√∫mero da √∫ltima coluna):
   ```powershell
   taskkill /F /PID <PID>
   ```

---

### ‚ùå Problema: Mem√≥rias n√£o s√£o salvas (erro de ID)

**Erro**: `Error processing memory action: ... Error: '<ID of the memory>'`

**Causa**: Modelo LLM (`tinyllama`) muito pequeno para gerar IDs estruturados

**Solu√ß√£o**:
1. Edite `.env` e mude para modelo maior:
   ```env
   LLM_MODEL=llama3.2:latest
   ```
2. Reinicie o servidor
3. Limpe mem√≥rias corrompidas:
   ```powershell
   .\reset_memory.bat
   ```

---

### ‚ùå Problema: add_memory muito lento (60+ segundos)

**Causa**: Modelo LLM grande (`llama3.1:8b`) sem GPU

**Solu√ß√µes**:

**Op√ß√£o 1**: Usar modelo menor (aceitar trade-off de qualidade)
```env
LLM_MODEL=llama3.2:latest  # ~35s por mem√≥ria
```

**Op√ß√£o 2**: Usar GPU (se dispon√≠vel)
- Ollama usa GPU automaticamente se detectar NVIDIA GPU
- Reduz tempo de 60s para 2-5s

**Op√ß√£o 3**: Usar API externa (requer chave API)
```env
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-...
LLM_MODEL=claude-3-haiku-20240307
```

---

### ‚ùå Problema: Claude Code n√£o v√™ o servidor MCP

**Sintomas**: `claude mcp list` n√£o mostra `mem0-lite` ou mostra "Failed to connect"

**Solu√ß√µes**:

1. Verifique se servidor est√° rodando:
   ```powershell
   curl http://127.0.0.1:8050/mcp/sse
   ```

2. Verifique configura√ß√£o do Claude:
   ```powershell
   notepad "$env:USERPROFILE\.claude.json"
   ```

   Deve ter:
   ```json
   {
     "mcpServers": {
       "mem0-lite": {
         "type": "sse",
         "url": "http://127.0.0.1:8050/mcp/sse"
       }
     }
   }
   ```

3. Reinicie o Claude Code

---

### ‚ùå Problema: Erro de importa√ß√£o `ModuleNotFoundError`

**Erro**: `ModuleNotFoundError: No module named 'mem0'` (ou outro m√≥dulo)

**Solu√ß√£o**:
1. Certifique-se de que o ambiente virtual est√° ativado:
   ```powershell
   .\.venv\Scripts\Activate.ps1
   ```
   (deve mostrar `(.venv)` no prompt)

2. Reinstale depend√™ncias:
   ```powershell
   pip install --force-reinstall mem0ai mcp fastapi uvicorn chromadb ollama python-dotenv pydantic
   ```

---

### ‚ùå Problema: Executar scripts .bat falha

**Erro**: N√£o pode executar `.bat` no PowerShell

**Solu√ß√£o**:
Use `cmd` ou `.\`:
```powershell
# Op√ß√£o 1: Via cmd
cmd /c start_mcp.bat

# Op√ß√£o 2: Com .\
.\start_mcp.bat
```

---

### üÜò Resetar Tudo

Se algo der muito errado e quiser recome√ßar do zero:

```powershell
cd C:\Dev\mcp-mem0-lite

# Parar servidor
taskkill /F /IM python.exe

# Limpar bancos de dados
.\reset_memory.bat

# Recriar ambiente virtual
rmdir /s /q .venv
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Reinstalar depend√™ncias
pip install --upgrade pip
pip install fastapi uvicorn python-dotenv pydantic mem0ai mcp chromadb ollama

# Reiniciar
.\start_mcp.bat
```

---

## üìö Recursos Adicionais

### Documenta√ß√£o Oficial

- **Mem0**: https://docs.mem0.ai/
- **MCP (Model Context Protocol)**: https://modelcontextprotocol.io/
- **Ollama**: https://ollama.com/
- **ChromaDB**: https://docs.trychroma.com/

### Comandos √öteis

```powershell
# Listar modelos Ollama instalados
ollama list

# Remover modelo n√£o usado
ollama rm <model_name>

# Ver logs do servidor (se rodando em background)
# (abrir a janela do servidor)

# Verificar uso de mem√≥ria do Ollama
tasklist /FI "IMAGENAME eq ollama.exe"

# Verificar processos Python rodando
tasklist /FI "IMAGENAME eq python.exe"
```

### Scripts Auxiliares

- `start_mcp.bat` - Iniciar Ollama + Servidor MCP (com verifica√ß√µes)
- `reset_memory.bat` - Limpar todas as mem√≥rias (apaga bancos de dados)
- `benchmark_speed.py` - Testar velocidade do add_memory
- `test_mcp_tools.py` - Testar todos os tools MCP

---

## ‚úÖ Checklist Final

Antes de considerar a instala√ß√£o completa, verifique:

- [ ] Python 3.12+ instalado e no PATH
- [ ] Ollama instalado e rodando
- [ ] Modelo `llama3.2:latest` baixado
- [ ] Modelo `nomic-embed-text` baixado
- [ ] Projeto copiado para `C:\Dev\mcp-mem0-lite`
- [ ] Ambiente virtual criado (`.venv/`)
- [ ] Depend√™ncias instaladas (mem0, mcp, fastapi, etc)
- [ ] Arquivo `.env` configurado com caminhos corretos
- [ ] Claude Code configurado (`~/.claude.json`)
- [ ] Servidor inicia sem erros (`.\start_mcp.bat`)
- [ ] Claude Code conecta ao servidor (`claude mcp list`)
- [ ] Consegue adicionar e listar mem√≥rias
- [ ] `list_all_user_ids` retorna seu username do Windows

Se todos os itens estiverem ‚úÖ, a instala√ß√£o est√° completa!

---

## üéâ Pr√≥ximos Passos

Agora que o servidor est√° instalado:

1. **Explorar os Tools MCP**:
   - `add_memory` - Adicionar mem√≥rias
   - `search_memory` - Busca sem√¢ntica
   - `list_memories` - Listar todas as mem√≥rias
   - `list_all_user_ids` - Ver usu√°rios com mem√≥rias
   - `delete_memory` - Apagar mem√≥ria espec√≠fica

2. **Usar no Claude Code**:
   - Pe√ßa ao Claude para salvar informa√ß√µes importantes
   - Use busca sem√¢ntica para recuperar contexto
   - Mem√≥rias persistem entre sess√µes

3. **Integrar com Gemini/Codex** (opcional):
   - Siga as instru√ß√µes da se√ß√£o 7.2 e 7.3
   - Compartilhe mem√≥rias entre diferentes AIs

4. **Ajustar Performance**:
   - Se muito lento: use modelo menor ou API externa
   - Se tem GPU: Ollama usar√° automaticamente
   - Consulte `PERFORMANCE_TUNING.md` para detalhes

---

**Instala√ß√£o criada em**: 2025-11-12
**Vers√£o do guia**: 1.0
**Testado em**: Windows 10/11, Python 3.12, Ollama 0.5+

Para suporte ou d√∫vidas, consulte a documenta√ß√£o oficial ou os recursos listados acima.
